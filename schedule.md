---
layout: page
title: RCQA@AAAI
subtitle: Reasoning for Complex QA Workshop 2020
---


# Invited Speakers<a name="speakers"></a>

We are pleased to present our invited speakers for RCQA-20!  

<div class="container">
  <div class="row">

{% for p in site.data.speakers %} {% capture id %}{{ p[0] }}{% endcapture %} {% include profile.html p=p %} {% endfor %}

</div>
</div>

For invited talk details, including abstracts, please go to [the speakers page](speakers.md).


# Open Poster Session<a name="open-poster-session"></a>

To encourage participation from the community at large, as well as to take advantage of AAAI 2020's co-location (in New York, NY) with leading industrial and academic research labs, we are pleased to announce an *Open Poster Session* on the day of the workshop. If you are a workshop registrant or AAAI participant, and have work that is [relevant to the topic of the RCQA workshop](https://rcqa-ws.github.io/cfp), we invite you to bring your work in the form of a poster for presentation during our [open poster session](program.md) -- to be held between 3pm and 4pm on the day of the workshop. 

Please send your poster (preferably, or a description of your work) to [Pavan Kapanipathi](mailto:kapanipa@us.ibm.com) with the subject line ``RCQA-20: Open Poster Session`` so that we can ensure the suitability and relevance of the work to the workshop. 

<sub><sup>RCQA-20 is non-archival, which means that presenting at our poster session should not preclude or be precluded by presentation of your work elsewhere. Open poster session participants will need to bring their own exhibition materials, as AAAI will only provide exhibition materials for papers accepted to the workshop program.</sup></sub>


# Workshop Program<a name="program"></a>

A preliminary draft of the workshop program is [available here](program.md).


# Accepted Papers<a name="accepted-papers"></a>

The following is a list of papers accepted to the workshop. Copies of the papers and an electronic proceedings will be made available after the camera ready deadline in January 2020. In the meantime, please feel free to reach out directly to the authors (where listed) to obtain a copy of their paper.

| **Title**                                                                                                       | **Authors**                                                              |
|-------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------|
|  Generating Helpful Responses for Intelligent Tech Support                                                  | *Wenhao Yu, Lingfei Wu, Shu Tao, Yu Deng, Qingkai Zeng and Meng Jiang* |
|  Giving Commands to a Self\-driving Car: A Multimodal Reasoner for Visual Grounding                         | *Thierry Deruyttere, Guillem Collell and Marie\-Francine Moens*        |
|  Humor Detection based on Paragraph Decomposition and BERT Fine\-Tuning                                     | *Hao Yang, Yao Deng, Minghan Wang, Ying Qin and Shiliang Sun*          |
|  Online Discussion Facilitation Support                                                                     | *Wen Gu and Takayuki Ito*                                              |
|  SMAC: An Interpretable Reasoning Network for Visual Question Answering                                     | *Minghan Wang, Hao Yang, Shiliang Sun, Yao Deng and Ying Qin*          |
|  Supervised Understanding of Word Embeddings                                                                | *Halid Ziya Yerebakan, Parmeet Bhatia and Yoshihisa Shinagawa*         |
|  SymbolNet: A Neural Symbolic Approach with Numerically\-aware Graph for Discrete Reasoning Over Paragraphs | *Xiangru Tang*                                                         |
|  Unsupervised Question Decomposition for Question Answering                                                 | *Authors Anonymous on Request*<sup>+</sup>                                          |
|  Why Do Masked Neural Language Models Still Need Commonsense Knowledge?                                     | *Authors Masked on Request*<sup>+</sup>           |


<sup>+</sup> <sub><sup>To maintain compliance with the [ACL 2020 anonymity restrictions](https://acl2020.org/calls/papers/#important-anonymity-period), these authors have requested that their papers be posted without identifying author information. We will make anonymized versions of these papers available online after the camera-ready deadline.</sup></sub> 
